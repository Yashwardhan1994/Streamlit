{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eadb05b-42be-46f1-89a1-458ec190c5a2",
   "metadata": {},
   "source": [
    "# Dataset Features\n",
    "\n",
    "1. **age**: Age of the client (numeric).\n",
    "2. **job**: Type of job (categorical: `'admin.'`, `'blue-collar'`, `'entrepreneur'`, `'housemaid'`, `'management'`, `'retired'`, `'self-employed'`, `'services'`, `'student'`, `'technician'`, `'unemployed'`, `'unknown'`).\n",
    "3. **marital**: Marital status (categorical: `'divorced'`, `'married'`, `'single'`, `'unknown'`; note: `'divorced'` includes divorced or widowed).\n",
    "4. **education**: Level of education (categorical: `'basic.4y'`, `'basic.6y'`, `'basic.9y'`, `'high.school'`, `'illiterate'`, `'professional.course'`, `'university.degree'`, `'unknown'`).\n",
    "5. **default**: Has credit in default? (categorical: `'no'`, `'yes'`, `'unknown'`).\n",
    "6. **housing**: Has housing loan? (categorical: `'no'`, `'yes'`, `'unknown'`).\n",
    "7. **loan**: Has personal loan? (categorical: `'no'`, `'yes'`, `'unknown'`).\n",
    "8. **contact**: Contact communication type (categorical: `'cellular'`, `'telephone'`).\n",
    "9. **month**: Last contact month of the year (categorical: `'jan'`, `'feb'`, `'mar'`, ..., `'nov'`, `'dec'`).\n",
    "10. **balance**: Account balance of the client.\n",
    "11. **day**: Last contact day of the month (numeric).\n",
    "12. **duration**: Last contact duration in seconds (numeric).  \n",
    "    **Important note**: This attribute highly affects the output target (e.g., if `duration=0`, then `y='no'`). However, the duration is unknown before the call and should only be included for benchmarking purposes. It should be discarded for a realistic predictive model.\n",
    "13. **campaign**: Number of contacts performed during this campaign for the client (numeric, includes last contact).\n",
    "14. **pdays**: Number of days since the client was last contacted from a previous campaign (numeric; `-1` means the client was not previously contacted).\n",
    "15. **previous**: Number of contacts performed before this campaign for the client (numeric).\n",
    "16. **poutcome**: Outcome of the previous marketing campaign (categorical: `'failure'`, `'nonexistent'`, `'success'`).\n",
    "17. **y** (Target Variable): Has the client subscribed to a term deposit? (binary: `'yes'`, `'no'`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d4c800-fa83-4d83-a055-fe5eca6371cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pk\n",
    "import streamlit as st\n",
    "from sklearn.preprocessing import OneHotEncoder , LabelEncoder , MinMaxScaler , StandardScaler\n",
    "from sklearn.model_selection import train_test_split , cross_val_score , GridSearchCV , RandomizedSearchCV , cross_validate\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score , classification_report , recall_score  , precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier , AdaBoostClassifier , GradientBoostingClassifier , RandomForestClassifier , VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import randint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4086a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Yash\\OneDrive\\Desktop\\GLIM\\Term 5\\ML-2\\Project\\Project\\bank-full.csv\" , sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f42d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e85c6",
   "metadata": {},
   "source": [
    "**At this Stage Unknown is not treated as Missing value, So we are not seeing any missing value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22692939",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f518e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e876cc2",
   "metadata": {},
   "source": [
    "**Changing Target Feature 'y' to 'Subscibed' so later it will not create problem while splitiing the data in X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adcd5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'y': 'Subscibed'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a59145",
   "metadata": {},
   "source": [
    "**Typecasting all the object data types to categorical for effiecient computing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3598ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.select_dtypes(include=['object']).columns] = data.select_dtypes(include=['object']).astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f06a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a5530",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d48cad4f",
   "metadata": {},
   "source": [
    "**Converting all the unknown data to Nan,So imputation can be applied to the same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9a2c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace 'unknown' and other placeholders with NaN\n",
    "data.replace(['unknown','?'], np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8807f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51052493",
   "metadata": {},
   "source": [
    "**Loop for counting all the Category and Numerical features  distinct values in Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba2468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    print(f\"Feature: {column}\")\n",
    "    print(data[column].value_counts())\n",
    "    print(\"\\n\" + \"-\"*10 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873e4ed",
   "metadata": {},
   "source": [
    "**checking for the all missing values in each feature across the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b928c32",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9556b8",
   "metadata": {},
   "source": [
    "**UNIVARIATE DATA ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd49ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loop for plotting all the histogram of all the integer features\n",
    "# data.hist(bins=50, color='silver', edgecolor='black', linewidth=1.0,\n",
    "#               xlabelsize=10, ylabelsize=10, grid=False)    \n",
    "# plt.tight_layout(rect=(0, 0, 2, 2))   \n",
    "# rt = plt.suptitle('Univariate Histogram Plots for all Int Features', x=0.85, y=2, fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1e903",
   "metadata": {},
   "source": [
    "** **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff288d",
   "metadata": {},
   "source": [
    "**COUNTPLOT FOR ALL THE CATEGORY AND OBJECT FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e492a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loop for plotting all the count plot of all the Category and object features.\n",
    "# for column in data.select_dtypes(include=['object', 'category']).columns:\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     sns.countplot(data=data, x=column, palette='Set1')\n",
    "#     plt.title(f'Count Plot for {column.capitalize()}')\n",
    "#     plt.xlabel(column.capitalize())\n",
    "#     plt.ylabel('Frequency')\n",
    "#     plt.xticks(rotation=45)  # Rotate x-axis labels if necessary\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece888f",
   "metadata": {},
   "source": [
    "**From the above countplot of Target variable y = Subscibed, It is clear that there is a CLASS IMBALANCE (Majority class (39922) is NO = Not Subscibed and minority class (5289) =Yes means subscibed) in the Target variable y=Subscibed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts('Subscibed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e65bb8",
   "metadata": {},
   "source": [
    "** **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b022de",
   "metadata": {},
   "source": [
    "**BIIVARIATE ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f091e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop for plotting all the count plot of all the Category and object features.\n",
    "for column in data.select_dtypes(include=['int', 'float']).columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=data, x='Subscibed', y=column, palette='Set1')\n",
    "    plt.title(f'Count Plot for {column.capitalize()}')\n",
    "    plt.xlabel(column.capitalize())\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels if necessary\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c6627e",
   "metadata": {},
   "source": [
    "**From the above BoxPlots graphs, it is evident tha most of the numerical features except days classification of Target variable will be weak classifier (not being able to classify the target Variables) due to the presence of Outliers in each numerical features with respect to the Target variable (Subscibed)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b989f",
   "metadata": {},
   "source": [
    "** **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1fc8a",
   "metadata": {},
   "source": [
    "**Barplot of Numerical variables against target Variabel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to plot\n",
    "variables = ['age', 'day', 'previous' , 'campaign','pdays','previous']\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(60, 24))\n",
    "\n",
    "# Loop through the variables and create subplots\n",
    "for i, var in enumerate(variables, 1):\n",
    "    plt.subplot(3, 3, i)  # Dynamically assign subplots in a 2x2 grid\n",
    "    sns.barplot(x=\"Subscibed\", y=var, data=data, palette=\"husl\")\n",
    "    plt.title(f\"{var.capitalize()} vs Subscribed\", fontsize=24)  # Dynamic title\n",
    "    plt.xlabel(var.capitalize(), fontsize=18)  # Dynamic x-axis label\n",
    "    plt.ylabel(\"Count\", fontsize=18)\n",
    "    plt.xticks(fontsize=18)  # Adjust x-axis tick font size\n",
    "    plt.yticks(fontsize=18)  # Adjust y-axis tick font size\n",
    "\n",
    "# Add legend and adjust layout\n",
    "plt.legend(title='Subscribed', fontsize=20, title_fontsize=16, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b07e5",
   "metadata": {},
   "source": [
    "**Customers with previous interactions and optimal contact timing (pdays) are more likely to subscribe, while repeated campaigns do not always lead to higher conversions. Age and day of contact show little influence on subscription likelihood**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be15a8",
   "metadata": {},
   "source": [
    "**  **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04cd37",
   "metadata": {},
   "source": [
    "**ScatterPlot of each Numerical variables against target Variabel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37326734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the pairs of x and y for scatterplots\n",
    "# plot_pairs = [\n",
    "#     ('age', 'balance'),\n",
    "#     ('balance', 'day'),\n",
    "#     ('balance', 'duration'),\n",
    "#     ('duration', 'age'),\n",
    "#     ('campaign', 'pdays'),\n",
    "#     ('pdays', 'previous'),\n",
    "#     ('previous', 'balance')\n",
    "# ]\n",
    "\n",
    "# # Set up the figure\n",
    "# plt.figure(figsize=(20, 12))\n",
    "\n",
    "# # Loop through the plot pairs and create scatterplots\n",
    "# for i, (x, y) in enumerate(plot_pairs, 1):\n",
    "#     plt.subplot(2, 4, i)  # Create subplots (2 rows, 4 columns)\n",
    "#     sns.scatterplot(x=x, y=y, hue='Subscibed', data=data, palette=\"Set1\")\n",
    "#     plt.title(f\"{x} vs {y}\")  # Dynamic title\n",
    "\n",
    "# # Adjust layout for better spacing\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Display the plots\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# # Define the variable combinations for 3D scatter plots\n",
    "# plot_combinations = [\n",
    "#     ('age', 'balance', 'day'),\n",
    "#     ('balance', 'day', 'duration'),\n",
    "#     ('day', 'duration', 'age'),\n",
    "#     ('duration', 'age', 'campaign'),\n",
    "#     ('campaign', 'pdays', 'previous'),\n",
    "#     ('pdays', 'previous', 'balance')\n",
    "# ]\n",
    "\n",
    "# # Loop through the combinations and create 3D scatter plots\n",
    "# for x, y, z in plot_combinations:\n",
    "#     fig = px.scatter_3d(\n",
    "#         data,\n",
    "#         x=x,\n",
    "#         y=y,\n",
    "#         z=z,\n",
    "#         color='Subscibed',  # Grouping by 'Subscibed'\n",
    "#         title=f\"3D Scatter Plot of {x} vs {y} vs {z}\",\n",
    "#         labels={x: x.capitalize(), y: y.capitalize(), z: z.capitalize()}  # Dynamic labels\n",
    "#     )\n",
    "#     # Show the plot\n",
    "#     fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da63ca",
   "metadata": {},
   "source": [
    "## Preparing Data for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9a525dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Subscibed'] , axis=1)\n",
    "y = data['Subscibed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e33be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size=0.3 , random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1aff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = X_train[['job', 'poutcome', 'contact', 'education']].dropna().mode().iloc[0]\n",
    "print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d885299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['job'].fillna(mode , inplace = True)\n",
    "X_train['job'].fillna(mode , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f171879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['contact'].fillna(mode , inplace = True)\n",
    "X_train['contact'].fillna(mode , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17667780",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = X_train['balance'].dropna().median()\n",
    "print(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515e571",
   "metadata": {},
   "source": [
    "**Filling Median value of Train (BALANCE) to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2359229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['balance'].fillna(median, inplace = True)\n",
    "X_train['balance'].fillna(median, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "152037e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder= LabelEncoder()\n",
    "\n",
    "X_train['education'] = labelEncoder.fit_transform(X_train['education'])\n",
    "X_test['education'] = labelEncoder.transform(X_test['education'])\n",
    "\n",
    "y_train = labelEncoder.fit_transform(y_train)\n",
    "\n",
    "y_test = labelEncoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43579f9d",
   "metadata": {},
   "source": [
    "**OneHotEncoding of all the Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cf31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X.select_dtypes(include=['category', 'object']).columns\n",
    "\n",
    "# Create and fit OneHotEncoder on the training data\n",
    "ohe = OneHotEncoder(drop='first', sparse_output=True, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform on the training data (will create sparse matrix)\n",
    "X_train_cat_sparse = ohe.fit_transform(X_train[categorical_columns])\n",
    "\n",
    "# Transform the test data using the same encoder (sparse matrix as well)\n",
    "X_test_cat_sparse = ohe.transform(X_test[categorical_columns])\n",
    "\n",
    "# Convert back to DataFrame for readability (converting sparse to dense format for visualization purposes)\n",
    "\n",
    "# It's optional to do this step, as the model will work with sparse format\n",
    "X_train_cat = pd.DataFrame.sparse.from_spmatrix(X_train_cat_sparse, columns=ohe.get_feature_names_out(categorical_columns), index=X_train.index)\n",
    "X_test_cat = pd.DataFrame.sparse.from_spmatrix(X_test_cat_sparse, \n",
    "columns=ohe.get_feature_names_out(categorical_columns), index=X_test.index)\n",
    "\n",
    "# Drop original categorical columns from X_train and X_test\n",
    "X_train = X_train.drop(columns=categorical_columns)\n",
    "X_test = X_test.drop(columns=categorical_columns)\n",
    "\n",
    "# Concatenate the encoded categorical columns back (sparse format will be preserved)\n",
    "X_train = pd.concat([X_train, X_train_cat], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_cat], axis=1)\n",
    "\n",
    "# Check the shapes to ensure alignment\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bad684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features to scale\n",
    "\n",
    "Numerical_columns = X.select_dtypes(include=['int']).columns\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform\n",
    "X_train[Numerical_columns] = scaler.fit_transform(X_train[Numerical_columns])\n",
    "\n",
    "# Transform the test data using the same scaler\n",
    "X_test[Numerical_columns] = scaler.transform(X_test[Numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5d64ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and instantiate the models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=25),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=25),\n",
    "    'VotingClassifier': VotingClassifier(estimators=[\n",
    "        ('dt1', DecisionTreeClassifier(criterion=\"entropy\", random_state=25)),\n",
    "        ('rf', RandomForestClassifier(random_state=25)),\n",
    "        ('dt2', DecisionTreeClassifier(random_state=25))\n",
    "    ], voting='soft'),\n",
    "    'BaggingClassifier': BaggingClassifier(random_state=25),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(random_state=25),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(random_state=25),\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=25),\n",
    "    'XGBClassifier': XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    'SVClassifier': SVC(random_state=25)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91a1bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, X_train, y_train, X_test, y_test):\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions for train and test datasets\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    # Calculate recall and precision on the test set\n",
    "    recall = recall_score(y_test, y_pred_test )  \n",
    "    precision = precision_score(y_test, y_pred_test) \n",
    "\n",
    "    return accuracy_test, accuracy_train, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store metrics for all models\n",
    "accuracy_scores_test = []\n",
    "accuracy_scores_train = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "# Loop through all models\n",
    "for name, model in models.items():\n",
    "    current_accuracy_test, current_accuracy_train, current_recall, current_precision = train_classifier(\n",
    "        model, X_train, y_train, X_test, y_test\n",
    "    )\n",
    "\n",
    "    # Print metrics for the current model\n",
    "    print(f\"\\nFor model: {name}\")\n",
    "    print(f\"Test Accuracy: {current_accuracy_test:.4f}\")\n",
    "    print(f\"Train Accuracy: {current_accuracy_train:.4f}\")\n",
    "    print(f\"Recall (Test): {current_recall:.4f}\")\n",
    "    print(f\"Precision (Test): {current_precision:.4f}\")\n",
    "\n",
    "    # Append metrics to their respective lists\n",
    "    accuracy_scores_test.append(current_accuracy_test)\n",
    "    accuracy_scores_train.append(current_accuracy_train)\n",
    "    precision_scores.append(current_precision)\n",
    "    recall_scores.append(current_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot metrics\n",
    "# def plot_metrics(models, accuracy_scores_test, accuracy_scores_train, precision_scores, recall_scores):\n",
    "#     # Set the bar width\n",
    "#     bar_width = 0.15\n",
    "#     # Positions of bars on the x-axis\n",
    "#     indices = np.arange(len(models))\n",
    "    \n",
    "#     # Plotting\n",
    "#     plt.figure(figsize=(16, 10))\n",
    "    \n",
    "#     # Bar plots for each metric\n",
    "#     plt.bar(indices, accuracy_scores_test, bar_width, label='Test Accuracy')\n",
    "#     plt.bar(indices + bar_width, accuracy_scores_train, bar_width, label='Train Accuracy')\n",
    "#     plt.bar(indices + 2 * bar_width, precision_scores, bar_width, label='Precision')\n",
    "#     plt.bar(indices + 3 * bar_width, recall_scores, bar_width, label='Recall')\n",
    "    \n",
    "#     # Labels and title\n",
    "#     plt.xlabel('Models', fontsize=14)\n",
    "#     plt.ylabel('Scores', fontsize=14)\n",
    "#     plt.title('Metrics Comparison Across Models', fontsize=16)\n",
    "#     plt.xticks(indices + 1.5 * bar_width, list(models.keys()), rotation=45, ha='right', fontsize=12)\n",
    "#     plt.legend()\n",
    "    \n",
    "#     # Add grid for better visualization\n",
    "#     plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "#     # Show plot\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Call the function to plot\n",
    "# plot_metrics(models, accuracy_scores_test, accuracy_scores_train, precision_scores, recall_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb279102",
   "metadata": {},
   "source": [
    "**HyperTuning RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model\n",
    "# Random_Forest_Classifier = RandomForestClassifier(random_state=25)\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_distributions = {\n",
    "#     'n_estimators':range(500,1000 ,250),  # Number of trees in the forest\n",
    "#     'max_features': ['auto'],  # Number of features to consider at every split\n",
    "#     'max_depth':range(50 ,100 ,30),   # Maximum depth of the tree\n",
    "#     'min_samples_split':range(30 , 100 ,50),          # Minimum number of samples required to split an internal node\n",
    "# }\n",
    "\n",
    "# # Set up RandomizedSearchCV\n",
    "# grid_search = GridSearchCV(estimator=Random_Forest_Classifier, param_grid=param_distributions, cv=5, n_jobs=-1, verbose=2, scoring=\"accuracy\")\n",
    "\n",
    "# # Perform the random search\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and the corresponding score\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# # Evaluate on the test set\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# print(\"\\nClassification Report on Test Data:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(\"\\nrecall on Test Data:\")\n",
    "# print(recall_score(y_test, y_pred))\n",
    "# print(\"\\nprecision on Test Data:\")\n",
    "# print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec813b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Trained_model.sav'\n",
    "pk.dump(RandomForestClassifier, open(filename , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a181ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = pk.load(open('Trained_model.sav' , 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb20d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
